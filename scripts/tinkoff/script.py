import subprocess
import sys
import pandas as pd

import time
from datetime import datetime, timedelta


def install_package(package):
    subprocess.check_call([sys.executable, "-m", "pip", "install", package])


try:
    from tinkoff.invest import Client, CandleInterval

    print("tinkoff-investments —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
except ImportError:
    print("–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é tinkoff-investments...")
    install_package("tinkoff-investments")
    from tinkoff.invest import Client, CandleInterval

try:
    import psycopg2
    from psycopg2.extras import execute_batch
except ImportError:
    print("–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é psycopg2-binary...")
    install_package("psycopg2-binary")
    import psycopg2
    from psycopg2.extras import execute_batch

ALL_TICKERS = [
    # –ë–∞–Ω–∫–∏ –∏ —Ñ–∏–Ω–∞–Ω—Å—ã
    "SBER",
    "SBERP",
    "VTBR",
    "TCSG",
    "CBOM",
    "BSPB",
    "SFIN",
    # –ù–µ—Ñ—Ç—å –∏ –≥–∞–∑
    "GAZP",
    "LKOH",
    "ROSN",
    "TATN",
    "TATNP",
    "NVTK",
    "SNGS",
    "SNGSP",
    # –ú–µ—Ç–∞–ª–ª—ã –∏ mining
    "GMKN",
    "PLZL",
    "ALRS",
    "POLY",
    "CHMF",
    "NLMK",
    "MAGN",
    "RUAL",
    # IT –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
    "YNDX",
    "OZON",
    "TCSG",
    "TTLK",
    # –†–∏—Ç–µ–π–ª –∏ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–∏–µ —Ç–æ–≤–∞—Ä—ã
    "MGNT",
    "FIXP",
    "X5",
    "LENT",
    "MVID",
    "BELU",
    "AQUA",
    # –¢–µ–ª–µ–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏
    "MTSS",
    "RTKM",
    "RTKMP",
    # –≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞ –∏ –∫–æ–º–º—É–Ω–∞–ª—å–Ω—ã–µ —É—Å–ª—É–≥–∏
    "IRAO",
    "HYDR",
    "FEES",
    "UPRO",
    "OGKB",
    "MRKC",
    "MRKP",
    # –¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç –∏ –ª–æ–≥–∏—Å—Ç–∏–∫–∞
    "AFLT",
    "FLOT",
    "NMTP",
    # –•–∏–º–∏—è –∏ —É–¥–æ–±—Ä–µ–Ω–∏—è
    "PHOR",
    "AKRN",
    # –†–∞–∑–Ω–æ–µ
    "PIKK",
    "MOEX",
    "AFKS",
    "LSRG",
    "RASP",
    "SVAV",
    "ENPG",
    "SMLT",
    "POSI",
    "MDMG",
    "ASTR",
    "UWGN",
    "TRMK",
    "RENI",
    "SOFL",
    "SGZH",
    "SELG",
    "LEAS",
    "VSMO",
    "IRKT",
]

# –°–ª–æ–≤–∞—Ä—å —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∫–æ–º–ø–∞–Ω–∏–π
TICKER_TO_COMPANY = {
    "SBER": "–ü–ê–û –°–±–µ—Ä–±–∞–Ω–∫",
    "SBERP": "–ü–ê–û –°–±–µ—Ä–±–∞–Ω–∫ (–ø)",
    "GAZP": "–ü–ê–û –ì–∞–∑–ø—Ä–æ–º",
    "LKOH": "–ü–ê–û –õ—É–∫–æ–π–ª",
    "GMKN": "–ü–ê–û –ì–ú–ö –ù–æ—Ä–Ω–∏–∫–µ–ª—å",
    "ROSN": "–ü–ê–û –†–æ—Å–Ω–µ—Ñ—Ç—å",
    "YNDX": "–ü–ê–û –Ø–Ω–¥–µ–∫—Å",
    "TATN": "–ü–ê–û –¢–∞—Ç–Ω–µ—Ñ—Ç—å",
    "TATNP": "–ü–ê–û –¢–∞—Ç–Ω–µ—Ñ—Ç—å (–ø)",
    "VTBR": "–ü–ê–û –ë–∞–Ω–∫ –í–¢–ë",
    "NVTK": "–ü–ê–û –ù–æ–≤–∞—Ç—ç–∫",
    "ALRS": "–ü–ê–û –ê–õ–†–û–°–ê",
    "POLY": "–ü–ê–û Polymetal",
    "PLZL": "–ü–ê–û –ü–æ–ª—é—Å",
    "MGNT": "–ü–ê–û –ú–∞–≥–Ω–∏—Ç",
    "MTSS": "–ü–ê–û –ú–¢–°",
    "RTKM": "–ü–ê–û –†–æ—Å—Ç–µ–ª–µ–∫–æ–º",
    "RTKMP": "–ü–ê–û –†–æ—Å—Ç–µ–ª–µ–∫–æ–º (–ø)",
    "HYDR": "–ü–ê–û –†—É—Å–ì–∏–¥—Ä–æ",
    "FEES": "–ü–ê–û –§–°–ö –ï–≠–°",
    "AFKS": "–ü–ê–û –ê–§–ö –°–∏—Å—Ç–µ–º–∞",
    "MOEX": "–ü–ê–û –ú–æ—Å–∫–æ–≤—Å–∫–∞—è –±–∏—Ä–∂–∞",
    "SNGS": "–ü–ê–û –°—É—Ä–≥—É—Ç–Ω–µ—Ñ—Ç–µ–≥–∞–∑",
    "SNGSP": "–ü–ê–û –°—É—Ä–≥—É—Ç–Ω–µ—Ñ—Ç–µ–≥–∞–∑ (–ø)",
    "BSPB": "–ü–ê–û –ë–∞–Ω–∫ –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
    "CBOM": "–ü–ê–û –ú–ö–ë",
    "TCSG": "–ü–ê–û TCS Group",
    "OZON": "–ü–ê–û Ozon",
    "PIKK": "–ü–ê–û –ü–ò–ö",
    "LSRG": "–ü–ê–û –õ–°–†",
    "CHMF": "–ü–ê–û –°–µ–≤–µ—Ä—Å—Ç–∞–ª—å",
    "NLMK": "–ü–ê–û –ù–õ–ú–ö",
    "MAGN": "–ü–ê–û –ú–ú–ö",
    "RUAL": "–ü–ê–û –†—É—Å–∞–ª",
    "PHOR": "–ü–ê–û –§–æ—Å–ê–≥—Ä–æ",
    "AKRN": "–ü–ê–û –ê–∫—Ä–æ–Ω",
    "AFLT": "–ü–ê–û –ê—ç—Ä–æ—Ñ–ª–æ—Ç",
    "FLOT": "–ü–ê–û –°–æ–≤–∫–æ–º—Ñ–ª–æ—Ç",
    "NMTP": "–ü–ê–û –ù–ú–¢–ü",
    "IRAO": "–ü–ê–û –ò–Ω—Ç–µ—Ä –†–ê–û",
    "UPRO": "–ü–ê–û –Æ–Ω–∏–ø—Ä–æ",
    "OGKB": "–ü–ê–û –û–ì–ö-2",
    "MRKC": "–ü–ê–û –†–æ—Å—Å–µ—Ç–∏ –¶–µ–Ω—Ç—Ä",
    "MRKP": "–ü–ê–û –†–æ—Å—Å–µ—Ç–∏ –¶–µ–Ω—Ç—Ä –∏ –ü—Ä–∏–≤–æ–ª–∂—å–µ",
    "FIXP": "–ü–ê–û Fix Price",
    "X5": "–ü–ê–û X5 Retail Group",
    "LENT": "–ü–ê–û –õ–µ–Ω—Ç–∞",
    "MVID": "–ü–ê–û –ú.–í–∏–¥–µ–æ",
    "BELU": "–ü–ê–û –ù–æ–≤–∞–ë–µ–≤ –ì—Ä—É–ø–ø",
    "AQUA": "–ü–ê–û –ò–Ω–ê—Ä–∫—Ç–∏–∫–∞",
    "SMLT": "–ì–ö –°–∞–º–æ–ª–µ—Ç",
    "POSI": "–ì—Ä—É–ø–ø–∞ –ü–æ–∑–∏—Ç–∏–≤",
    "MDMG": "–ú–ö–ü–ê–û –ú–î –ú–µ–¥–∏–∫–∞–ª –ì—Ä—É–ø",
    "ASTR": "–ì—Ä—É–ø–ø–∞ –ê—Å—Ç—Ä–∞",
    "UWGN": "–ü–ê–û –ù–ü–ö –û–í–ö",
    "TRMK": "–ü–ê–û –¢–ú–ö",
    "RENI": "–ü–ê–û –†–µ–Ω–µ—Å—Å–∞–Ω—Å –°—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏–µ",
    "SOFL": "–ü–ê–û –°–æ—Ñ—Ç–ª–∞–π–Ω",
    "SGZH": "–ü–ê–û –°–µ–≥–µ–∂–∞",
    "SELG": "–ü–ê–û –°–µ–ª–∏–≥–¥–∞—Ä",
    "LEAS": "–ü–ê–û –õ–ö –ï–≤—Ä–æ–ø–ª–∞–Ω",
    "VSMO": "–ü–ê–û –í–°–ú–ü–û-–ê–í–ò–°–ú–ê",
    "IRKT": "–ü–ê–û –ò—Ä–∫—É—Ç",
    "RASP": "–ü–ê–û –†–∞—Å–ø–∞–¥—Å–∫–∞—è",
    "SVAV": "–ü–ê–û –°–æ–ª–ª–µ—Ä—Å",
    "ENPG": "–ú–ö–ü–ê–û –≠–Ω+ –ì—Ä—É–ø",
    "TTLK": "–ü–ê–û –¢-–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏",
}


class DatabaseManager:
    def __init__(self, db_config):
        self.db_config = db_config
        self.conn = None
        self.connect()
        self.create_tables()

    def connect(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            self.conn = psycopg2.connect(**self.db_config)
            print("‚úÖ –£—Å–ø–µ—à–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ PostgreSQL")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ PostgreSQL: {e}")
            raise

    def create_tables(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç"""
        try:
            with self.conn.cursor() as cursor:
                # –¢–∞–±–ª–∏—Ü–∞ –∫–æ–º–ø–∞–Ω–∏–π
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS companies (
                        id SERIAL PRIMARY KEY,
                        ticker VARCHAR(20) UNIQUE NOT NULL,
                        name TEXT NOT NULL,
                        figi VARCHAR(50) UNIQUE NOT NULL,
                        currency VARCHAR(10),
                        lot INTEGER,
                        min_price_increment DECIMAL(10,6),
                        sector TEXT,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)

                # –¢–∞–±–ª–∏—Ü–∞ —Å–≤–µ—á–µ–π
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS candles (
                        id SERIAL PRIMARY KEY,
                        ticker VARCHAR(20) REFERENCES companies(ticker),
                        datetime TIMESTAMP NOT NULL,
                        open DECIMAL(15,6),
                        high DECIMAL(15,6),
                        low DECIMAL(15,6),
                        close DECIMAL(15,6),
                        volume BIGINT,
                        is_complete BOOLEAN,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        UNIQUE(ticker, datetime)
                    )
                """)

                # –¢–∞–±–ª–∏—Ü–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å–±–æ—Ä–æ–≤
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS collection_metadata (
                        id SERIAL PRIMARY KEY,
                        collection_timestamp TIMESTAMP NOT NULL,
                        total_searched INTEGER NOT NULL,
                        found_stocks INTEGER NOT NULL,
                        not_found_count INTEGER NOT NULL,
                        collection_years INTEGER NOT NULL,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)

                # –¢–∞–±–ª–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS not_found_tickers (
                        id SERIAL PRIMARY KEY,
                        collection_id INTEGER REFERENCES collection_metadata(id),
                        ticker VARCHAR(20) NOT NULL,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)

                # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
                cursor.execute(
                    "CREATE INDEX IF NOT EXISTS idx_candles_ticker_datetime ON candles(ticker, datetime)"
                )
                cursor.execute(
                    "CREATE INDEX IF NOT EXISTS idx_candles_datetime ON candles(datetime)"
                )
                cursor.execute(
                    "CREATE INDEX IF NOT EXISTS idx_companies_ticker ON companies(ticker)"
                )

                self.conn.commit()
                print("‚úÖ –¢–∞–±–ª–∏—Ü—ã —Å–æ–∑–¥–∞–Ω—ã/–ø—Ä–æ–≤–µ—Ä–µ–Ω—ã")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü: {e}")
            self.conn.rollback()
            raise

    def save_company_info(self, company_info):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–º–ø–∞–Ω–∏–∏"""
        try:
            with self.conn.cursor() as cursor:
                cursor.execute(
                    """
                    INSERT INTO companies (ticker, name, figi, currency, lot, min_price_increment, sector)
                    VALUES (%s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (ticker) DO UPDATE SET
                        name = EXCLUDED.name,
                        figi = EXCLUDED.figi,
                        currency = EXCLUDED.currency,
                        lot = EXCLUDED.lot,
                        min_price_increment = EXCLUDED.min_price_increment,
                        sector = EXCLUDED.sector,
                        updated_at = CURRENT_TIMESTAMP
                """,
                    (
                        company_info["ticker"],
                        company_info["name"],
                        company_info["figi"],
                        company_info["currency"],
                        company_info["lot"],
                        company_info["min_price_increment"],
                        company_info["sector"],
                    ),
                )
                self.conn.commit()
                return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–∏ {company_info['ticker']}: {e}")
            self.conn.rollback()
            return False

    def save_candles_batch(self, ticker, candles_df):
        """–ü–∞–∫–µ—Ç–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–≤–µ—á–µ–π"""
        if candles_df.empty:
            return True

        try:
            with self.conn.cursor() as cursor:
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
                data_tuples = [
                    (
                        ticker,
                        row["datetime"],
                        row["open"],
                        row["high"],
                        row["low"],
                        row["close"],
                        row["volume"],
                        row["is_complete"],
                    )
                    for _, row in candles_df.iterrows()
                ]

                # –ü–∞–∫–µ—Ç–Ω–∞—è –≤—Å—Ç–∞–≤–∫–∞
                execute_batch(
                    cursor,
                    """
                    INSERT INTO candles (ticker, datetime, open, high, low, close, volume, is_complete)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (ticker, datetime) DO UPDATE SET
                        open = EXCLUDED.open,
                        high = EXCLUDED.high,
                        low = EXCLUDED.low,
                        close = EXCLUDED.close,
                        volume = EXCLUDED.volume,
                        is_complete = EXCLUDED.is_complete
                """,
                    data_tuples,
                )

                self.conn.commit()
                print(f"   üìä –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(data_tuples)} —Å–≤–µ—á–µ–π –¥–ª—è {ticker}")
                return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–≤–µ—á–µ–π –¥–ª—è {ticker}: {e}")
            self.conn.rollback()
            return False

    def save_collection_metadata(self, metadata, not_found_tickers):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å–±–æ—Ä–∞"""
        try:
            with self.conn.cursor() as cursor:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                cursor.execute(
                    """
                    INSERT INTO collection_metadata 
                    (collection_timestamp, total_searched, found_stocks, not_found_count, collection_years)
                    VALUES (%s, %s, %s, %s, %s)
                    RETURNING id
                """,
                    (
                        metadata["timestamp"],
                        metadata["total_searched"],
                        metadata["found_stocks"],
                        metadata["not_found_count"],
                        metadata["collection_years"],
                    ),
                )

                collection_id = cursor.fetchone()[0]

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–∏–∫–µ—Ä—ã
                if not_found_tickers:
                    not_found_tuples = [
                        (collection_id, ticker) for ticker in not_found_tickers
                    ]
                    execute_batch(
                        cursor,
                        """
                        INSERT INTO not_found_tickers (collection_id, ticker)
                        VALUES (%s, %s)
                    """,
                        not_found_tuples,
                    )

                self.conn.commit()
                print(f"‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã (ID: {collection_id})")
                return collection_id

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}")
            self.conn.rollback()
            return None

    def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö"""
        if self.conn:
            self.conn.close()
            print("‚úÖ –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å PostgreSQL –∑–∞–∫—Ä—ã—Ç–æ")


class CompleteDataCollector:
    def __init__(self, token):
        self.token = token

    def find_available_stocks(self):
        """–ü–æ–∏—Å–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞–∫—Ü–∏–π –∏–∑ —Å–ø–∏—Å–∫–∞"""
        print(f"–í—Å–µ–≥–æ —Ç–∏–∫–µ—Ä–æ–≤ –≤ —Å–ø–∏—Å–∫–µ: {len(ALL_TICKERS)}")

        with Client(self.token) as client:
            try:
                all_shares = client.instruments.shares().instruments
                print(f"–í—Å–µ–≥–æ –∞–∫—Ü–∏–π –≤ Tinkoff API: {len(all_shares)}")

                available_stocks = []
                not_found = []

                # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
                shares_by_ticker = {}
                for share in all_shares:
                    shares_by_ticker[share.ticker] = share

                for ticker in ALL_TICKERS:
                    if ticker in shares_by_ticker:
                        share = shares_by_ticker[ticker]

                        if share.currency == "rub" and share.buy_available_flag:
                            stock_info = {
                                "ticker": share.ticker,
                                "figi": share.figi,
                                "name": TICKER_TO_COMPANY.get(ticker, share.name),
                                "api_name": share.name,
                                "currency": share.currency,
                                "lot": share.lot,
                                "min_price_increment": self._quotation_to_float(
                                    share.min_price_increment
                                ),
                                "sector": share.sector
                                if hasattr(share, "sector")
                                else "–ù–µ —É–∫–∞–∑–∞–Ω",
                            }
                            available_stocks.append(stock_info)
                            print(f"{ticker}: {stock_info['name']}")
                        else:
                            not_found.append(ticker)
                            print(f"{ticker}: –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è —Ç–æ—Ä–≥–æ–≤–ª–∏")
                    else:
                        not_found.append(ticker)
                        print(f"{ticker}: –Ω–µ –Ω–∞–π–¥–µ–Ω")

                print("\n –ò–¢–û–ì–û:")
                print(f"   –ù–∞–π–¥–µ–Ω–æ: {len(available_stocks)} –∞–∫—Ü–∏–π")
                print(f"   –ù–µ –Ω–∞–π–¥–µ–Ω–æ: {len(not_found)} –∞–∫—Ü–∏–π")

                if not_found:
                    print(f"   –ù–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ: {', '.join(not_found)}")

                return available_stocks, not_found

            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –∞–∫—Ü–∏–π: {e}")
                return [], ALL_TICKERS

    def collect_extended_data(self, stocks_info, years=10):
        """–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–µ–π"""
        all_data = {}
        failed_tickers = []

        print(f"\n –ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∑–∞ {years} –ª–µ—Ç...")
        print(f" –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {len(stocks_info)} –∞–∫—Ü–∏–π")
        print("-" * 60)

        for i, stock in enumerate(stocks_info, 1):
            try:
                print(f" [{i:2d}/{len(stocks_info)}] {stock['ticker']}...")

                # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —á–∞—Å—Ç—è–º
                candles_df = self._collect_data_in_chunks(stock["figi"], years=years)

                if candles_df is not None and len(candles_df) > 100:
                    all_data[stock["ticker"]] = {
                        "data": candles_df,
                        "info": stock,
                        "first_date": candles_df["datetime"].min(),
                        "last_date": candles_df["datetime"].max(),
                        "candle_count": len(candles_df),
                        "data_quality": self._assess_data_quality(candles_df),
                        "period_years": (
                            candles_df["datetime"].max() - candles_df["datetime"].min()
                        ).days
                        / 365.25,
                    }

                    print(f"   –£—Å–ø–µ—à–Ω–æ: {len(candles_df)} —Å–≤–µ—á–µ–π")
                    print(
                        f"   –ü–µ—Ä–∏–æ–¥: {candles_df['datetime'].min().date()} - {candles_df['datetime'].max().date()}"
                    )

                else:
                    failed_tickers.append(stock["ticker"])
                    print(
                        f"   –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö: {len(candles_df) if candles_df else 0} —Å–≤–µ—á–µ–π"
                    )

                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                time.sleep(0.3)

            except Exception as e:
                failed_tickers.append(stock["ticker"])
                print(f"   –û—à–∏–±–∫–∞: {e}")
                continue

        print("-" * 60)
        print(f"–£—Å–ø–µ—à–Ω–æ —Å–æ–±—Ä–∞–Ω–æ: {len(all_data)} –∞–∫—Ü–∏–π")
        if failed_tickers:
            print(f" –ü—Ä–æ–±–ª–µ–º—ã —Å: {', '.join(failed_tickers)}")

        return all_data

    def _collect_data_in_chunks(self, figi, years=10, chunk_years=3):
        """–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —á–∞—Å—Ç—è–º–∏"""
        all_chunks = []
        end_time = datetime.utcnow()

        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø–µ—Ä–∏–æ–¥—ã
        for chunk_start in range(0, years, chunk_years):
            chunk_end = min(chunk_start + chunk_years, years)

            start_time = end_time - timedelta(days=chunk_end * 365)
            chunk_start_time = end_time - timedelta(days=chunk_start * 365)

            try:
                chunk_data = self._get_candles_period(
                    figi, start_time, chunk_start_time
                )
                if chunk_data is not None and len(chunk_data) > 0:
                    all_chunks.append(chunk_data)

                time.sleep(0.2)

            except Exception:
                continue

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —á–∞–Ω–∫–∏
        if all_chunks:
            combined_df = pd.concat(all_chunks, ignore_index=True)
            combined_df = combined_df.drop_duplicates(subset=["datetime"]).sort_values(
                "datetime"
            )
            return combined_df
        else:
            return pd.DataFrame()

    def _get_candles_period(
        self, figi, start_time, end_time, interval=CandleInterval.CANDLE_INTERVAL_DAY
    ):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤–µ—á–µ–π –∑–∞ –ø–µ—Ä–∏–æ–¥"""
        with Client(self.token) as client:
            try:
                candles = client.get_all_candles(
                    figi=figi, from_=start_time, to=end_time, interval=interval
                )
                return self._candles_to_dataframe(candles)
            except Exception:
                return pd.DataFrame()

    def _candles_to_dataframe(self, candles):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å–≤–µ—á–µ–π –≤ DataFrame"""
        data = []
        for candle in candles:
            data.append(
                {
                    "datetime": candle.time,
                    "open": self._quotation_to_float(candle.open),
                    "high": self._quotation_to_float(candle.high),
                    "low": self._quotation_to_float(candle.low),
                    "close": self._quotation_to_float(candle.close),
                    "volume": candle.volume,
                    "is_complete": candle.is_complete,
                }
            )
        return pd.DataFrame(data) if data else pd.DataFrame()

    def _quotation_to_float(self, quotation):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è Quotation –≤ float"""
        if hasattr(quotation, "units") and hasattr(quotation, "nano"):
            return quotation.units + quotation.nano / 1e9
        return float(quotation)

    def _assess_data_quality(self, df):
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö"""
        if len(df) == 0:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"

        missing_data = df[["open", "high", "low", "close"]].isnull().sum().sum()
        zero_volume = (df["volume"] == 0).sum()

        quality_score = (len(df) - missing_data - zero_volume / 10) / len(df)

        if quality_score > 0.95:
            return "–û—Ç–ª–∏—á–Ω–æ–µ"
        elif quality_score > 0.8:
            return "–•–æ—Ä–æ—à–µ–µ"
        elif quality_score > 0.6:
            return "–£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–µ"
        else:
            return "–ü–ª–æ—Ö–æ–µ"


class CompleteDataDBManager:
    def __init__(self, db_config):
        self.db_manager = DatabaseManager(db_config)

    def save_all_data(
        self, all_data, available_stocks, not_found_tickers, collection_years
    ):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        timestamp = datetime.now()

        print("\n –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ PostgreSQL...")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–º–ø–∞–Ω–∏—è—Ö
        companies_saved = 0
        for stock in available_stocks:
            if self.db_manager.save_company_info(stock):
                companies_saved += 1
        print(f"   –ö–æ–º–ø–∞–Ω–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {companies_saved}/{len(available_stocks)}")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–≤–µ—á–µ–π
        candles_saved = 0
        for ticker, data in all_data.items():
            if self.db_manager.save_candles_batch(ticker, data["data"]):
                candles_saved += 1
        print(f"   –°–≤–µ—á–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {candles_saved}/{len(all_data)}")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        metadata = {
            "timestamp": timestamp,
            "total_searched": len(ALL_TICKERS),
            "found_stocks": len(all_data),
            "not_found_count": len(not_found_tickers),
            "collection_years": collection_years,
        }

        collection_id = self.db_manager.save_collection_metadata(
            metadata, not_found_tickers
        )

        # –°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç—á–µ—Ç–∞
        self._create_analysis_report(all_data, timestamp)

        return timestamp, collection_id

    def _create_analysis_report(self, all_data, timestamp):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        analysis_data = []

        for ticker, data in all_data.items():
            df = data["data"]
            if len(df) > 0:
                returns = df["close"].pct_change()

                analysis_data.append(
                    {
                        "ticker": ticker,
                        "name": data["info"]["name"],
                        "sector": data["info"]["sector"],
                        "first_date": data["first_date"].strftime("%Y-%m-%d"),
                        "last_date": data["last_date"].strftime("%Y-%m-%d"),
                        "total_candles": len(df),
                        "period_years": round(data["period_years"], 1),
                        "start_price": df["close"].iloc[0],
                        "end_price": df["close"].iloc[-1],
                        "total_return_percent": (
                            df["close"].iloc[-1] - df["close"].iloc[0]
                        )
                        / df["close"].iloc[0]
                        * 100,
                        "max_price": df["high"].max(),
                        "min_price": df["low"].min(),
                        "avg_daily_volume": df["volume"].mean(),
                        "volatility_percent": returns.std() * 100
                        if len(returns) > 1
                        else 0,
                        "data_quality": data["data_quality"],
                    }
                )

        analysis_df = pd.DataFrame(analysis_data)

        # –í—ã–≤–æ–¥ —Å–≤–æ–¥–∫–∏ –≤ –∫–æ–Ω—Å–æ–ª—å
        print("\n –°–í–û–î–ö–ê –ü–û –í–°–ï–ú –ö–û–ú–ü–ê–ù–ò–Ø–ú:")
        print("=" * 60)
        print(f" –ê–∫—Ü–∏–π —Å–æ–±—Ä–∞–Ω–æ: {len(analysis_df)}")
        print(f" –í—Å–µ–≥–æ —Å–≤–µ—á–µ–π: {analysis_df['total_candles'].sum():,}")
        print(f" –°—Ä–µ–¥–Ω–∏–π –ø–µ—Ä–∏–æ–¥: {analysis_df['period_years'].mean():.1f} –ª–µ—Ç")

        # –¢–æ–ø-5 –ø–æ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
        if len(analysis_df) > 0:
            print("\n –¢–û–ü-5 –ü–û –î–û–•–û–î–ù–û–°–¢–ò:")
            top_return = analysis_df.nlargest(5, "total_return_percent")[
                ["ticker", "name", "total_return_percent"]
            ]
            for _, row in top_return.iterrows():
                symbol = "üü¢" if row["total_return_percent"] > 0 else "üî¥"
                print(
                    f"   {symbol} {row['ticker']}: {row['total_return_percent']:+.1f}%"
                )

    def close_connection(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö"""
        self.db_manager.close()


def show_database_stats(db_config):
    """–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    try:
        db_manager = DatabaseManager(db_config)

        with db_manager.conn.cursor() as cursor:
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ–º–ø–∞–Ω–∏–π
            cursor.execute("SELECT COUNT(*) FROM companies")
            companies_count = cursor.fetchone()[0]

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–≤–µ—á–µ–π
            cursor.execute("SELECT COUNT(*) FROM candles")
            candles_count = cursor.fetchone()[0]

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–∞—Ç–∞–º
            cursor.execute("SELECT MIN(datetime), MAX(datetime) FROM candles")
            min_date, max_date = cursor.fetchone()

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–±–æ—Ä–∫–∞–º
            cursor.execute(
                "SELECT COUNT(*), MAX(collection_timestamp) FROM collection_metadata"
            )
            collections_count, last_collection = cursor.fetchone()

        db_manager.close()

        print("\n –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ë–ê–ó–´ –î–ê–ù–ù–´–•:")
        print("-" * 50)
        print(f" –ö–æ–º–ø–∞–Ω–∏–π: {companies_count}")
        print(f" –°–≤–µ—á–µ–π: {candles_count:,}")
        print(f" –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {min_date.date()} - {max_date.date()}")
        print(f" –°–±–æ—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö: {collections_count}")
        print(f" –ü–æ—Å–ª–µ–¥–Ω—è—è —Å–±–æ—Ä–∫–∞: {last_collection}")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")


def main_complete_collection():
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö PostgreSQL
    DB_CONFIG = {
        "dbname": "russian-stocks-prediction-ml-dl",
        "user": "root",
        "password": "groot",
        "host": "185.70.105.233",
        "port": "5432",
    }

    # –¢–û–ö–ï–ù Tinkoff
    TINKOFF_TOKEN = "TOKEN"

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
    COLLECTION_YEARS = 10  # –õ–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏

    print(" –ü–û–õ–ù–´–ô –°–ë–û–† –î–ê–ù–ù–´–• –í POSTGRESQL")
    print("=" * 60)
    print(f" –ö–æ–º–ø–∞–Ω–∏–π –≤ —Å–ø–∏—Å–∫–µ: {len(ALL_TICKERS)}")
    print(f" –ü–µ—Ä–∏–æ–¥ —Å–±–æ—Ä–∞: {COLLECTION_YEARS} –ª–µ—Ç")
    print("=" * 60)

    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        collector = CompleteDataCollector(TINKOFF_TOKEN)
        data_manager = CompleteDataDBManager(DB_CONFIG)

        # –®–∞–≥ 1: –ü–æ–∏—Å–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞–∫—Ü–∏–π
        available_stocks, not_found = collector.find_available_stocks()

        if not available_stocks:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞–∫—Ü–∏–π!")
            return

        # –®–∞–≥ 2: –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
        print(f"\n –ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∑–∞ {COLLECTION_YEARS} –ª–µ—Ç...")
        all_data = collector.collect_extended_data(
            available_stocks, years=COLLECTION_YEARS
        )

        if all_data:
            # –®–∞–≥ 3: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
            timestamp, collection_id = data_manager.save_all_data(
                all_data, available_stocks, not_found, COLLECTION_YEARS
            )

            print("\n –ü–û–õ–ù–´–ô –°–ë–û–† –î–ê–ù–ù–´–• –ó–ê–í–ï–†–®–ï–ù!")
            print(" –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ PostgreSQL")
            print(f" ID —Å–±–æ—Ä–∫–∏: {collection_id}")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            show_database_stats(DB_CONFIG)

        else:
            print(" –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ")

        # –ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        data_manager.close_connection()

    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")


def quick_db_stats(db_config):
    """–ë—ã—Å—Ç—Ä–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    try:
        db_manager = DatabaseManager(db_config)

        with db_manager.conn.cursor() as cursor:
            # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            cursor.execute("""
                SELECT 
                    COUNT(DISTINCT ticker) as companies_count,
                    COUNT(*) as candles_count,
                    MIN(datetime) as first_date,
                    MAX(datetime) as last_date
                FROM candles
            """)
            stats = cursor.fetchone()

            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–æ–º–ø–∞–Ω–∏—è–º
            cursor.execute("""
                SELECT ticker, COUNT(*) as candle_count
                FROM candles 
                GROUP BY ticker 
                ORDER BY candle_count DESC
                LIMIT 10
            """)
            top_companies = cursor.fetchall()

        db_manager.close()

        print("\n –ë–´–°–¢–†–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f" –ö–æ–º–ø–∞–Ω–∏–π: {stats[0]}")
        print(f" –°–≤–µ—á–µ–π: {stats[1]:,}")
        print(f" –ü–µ—Ä–∏–æ–¥: {stats[2].date()} - {stats[3].date()}")

        print("\n –¢–û–ü-10 –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–≤–µ—á–µ–π:")
        for ticker, count in top_companies:
            print(f"   {ticker}: {count:,} —Å–≤–µ—á–µ–π")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")


if __name__ == "__main__":
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    DB_CONFIG = {
        "dbname": "russian-stocks-prediction-ml-dl",
        "user": "root",
        "password": "groot",
        "host": "185.70.105.233",
        "port": "5432",
    }

    # –û—Å–Ω–æ–≤–Ω–æ–π —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
    main_complete_collection()

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: –±—ã—Å—Ç—Ä–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    quick_db_stats(DB_CONFIG)
