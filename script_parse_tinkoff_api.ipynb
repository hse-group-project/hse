{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66008e3c-c05a-4ec9-8d98-b5deedc42ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é tinkoff-investments...\n",
      "Collecting tinkoff-investments\n",
      "  Downloading tinkoff_investments-0.2.0b117-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting cachetools<6.0.0,>=5.2.0 (from tinkoff-investments)\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting deprecation<3.0.0,>=2.1.0 (from tinkoff-investments)\n",
      "  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting grpcio<2.0.0,>=1.59.3 (from tinkoff-investments)\n",
      "  Downloading grpcio-1.76.0-cp313-cp313-macosx_11_0_universal2.whl.metadata (3.7 kB)\n",
      "Collecting protobuf<5.0.0,>=4.25.1 (from tinkoff-investments)\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /Users/vanoney30/Library/Python/3.13/lib/python/site-packages (from tinkoff-investments) (2.9.0.post0)\n",
      "Collecting tinkoff<0.2.0,>=0.1.1 (from tinkoff-investments)\n",
      "  Downloading tinkoff-0.1.1-py3-none-any.whl.metadata (511 bytes)\n",
      "Requirement already satisfied: packaging in /Users/vanoney30/Library/Python/3.13/lib/python/site-packages (from deprecation<3.0.0,>=2.1.0->tinkoff-investments) (24.2)\n",
      "Requirement already satisfied: typing-extensions~=4.12 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from grpcio<2.0.0,>=1.59.3->tinkoff-investments) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/vanoney30/Library/Python/3.13/lib/python/site-packages (from python-dateutil<3.0.0,>=2.8.2->tinkoff-investments) (1.17.0)\n",
      "Downloading tinkoff_investments-0.2.0b117-py3-none-any.whl (253 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading grpcio-1.76.0-cp313-cp313-macosx_11_0_universal2.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Downloading tinkoff-0.1.1-py3-none-any.whl (1.0 kB)\n",
      "Installing collected packages: tinkoff, protobuf, grpcio, deprecation, cachetools, tinkoff-investments\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6/6\u001b[0m [tinkoff-investments]precation]\n",
      "\u001b[1A\u001b[2KSuccessfully installed cachetools-5.5.2 deprecation-2.1.0 grpcio-1.76.0 protobuf-4.25.8 tinkoff-0.1.1 tinkoff-investments-0.2.0b117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TOKEN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 734\u001b[0m\n\u001b[1;32m    725\u001b[0m DB_CONFIG \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdbname\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrussian-stocks-prediction-ml-dl\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    727\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mport\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5432\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    731\u001b[0m }\n\u001b[1;32m    733\u001b[0m \u001b[38;5;66;03m# –û—Å–Ω–æ–≤–Ω–æ–π —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m \u001b[43mmain_complete_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;66;03m# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: –±—ã—Å—Ç—Ä–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\u001b[39;00m\n\u001b[1;32m    737\u001b[0m quick_db_stats(DB_CONFIG)\n",
      "Cell \u001b[0;32mIn[1], line 633\u001b[0m, in \u001b[0;36mmain_complete_collection\u001b[0;34m()\u001b[0m\n\u001b[1;32m    624\u001b[0m DB_CONFIG \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdbname\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrussian-stocks-prediction-ml-dl\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mport\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5432\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    630\u001b[0m }\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# –¢–û–ö–ï–ù Tinkoff\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m TINKOFF_TOKEN \u001b[38;5;241m=\u001b[39m \u001b[43mTOKEN\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;66;03m# –ù–∞—Å—Ç—Ä–æ–π–∫–∏\u001b[39;00m\n\u001b[1;32m    636\u001b[0m COLLECTION_YEARS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# –õ–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TOKEN' is not defined"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "try:\n",
    "    from tinkoff.invest import Client, CandleInterval\n",
    "    print(\"tinkoff-investments —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
    "except ImportError:\n",
    "    print(\"–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é tinkoff-investments...\")\n",
    "    install_package(\"tinkoff-investments\")\n",
    "    from tinkoff.invest import Client, CandleInterval\n",
    "\n",
    "try:\n",
    "    import psycopg2\n",
    "    from psycopg2.extras import execute_batch\n",
    "except ImportError:\n",
    "    print(\"–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é psycopg2-binary...\")\n",
    "    install_package(\"psycopg2-binary\")\n",
    "    import psycopg2\n",
    "    from psycopg2.extras import execute_batch\n",
    "\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "ALL_TICKERS = [\n",
    "    # –ë–∞–Ω–∫–∏ –∏ —Ñ–∏–Ω–∞–Ω—Å—ã\n",
    "    \"SBER\", \"SBERP\", \"VTBR\", \"TCSG\", \"CBOM\", \"BSPB\", \"SFIN\",\n",
    "    \n",
    "    # –ù–µ—Ñ—Ç—å –∏ –≥–∞–∑\n",
    "    \"GAZP\", \"LKOH\", \"ROSN\", \"TATN\", \"TATNP\", \"NVTK\", \"SNGS\", \"SNGSP\",\n",
    "    \n",
    "    # –ú–µ—Ç–∞–ª–ª—ã –∏ mining\n",
    "    \"GMKN\", \"PLZL\", \"ALRS\", \"POLY\", \"CHMF\", \"NLMK\", \"MAGN\", \"RUAL\",\n",
    "    \n",
    "    # IT –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏\n",
    "    \"YNDX\", \"OZON\", \"TCSG\", \"TTLK\",\n",
    "    \n",
    "    # –†–∏—Ç–µ–π–ª –∏ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–∏–µ —Ç–æ–≤–∞—Ä—ã\n",
    "    \"MGNT\", \"FIXP\", \"X5\", \"LENT\", \"MVID\", \"BELU\", \"AQUA\",\n",
    "    \n",
    "    # –¢–µ–ª–µ–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏\n",
    "    \"MTSS\", \"RTKM\", \"RTKMP\",\n",
    "    \n",
    "    # –≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞ –∏ –∫–æ–º–º—É–Ω–∞–ª—å–Ω—ã–µ —É—Å–ª—É–≥–∏\n",
    "    \"IRAO\", \"HYDR\", \"FEES\", \"UPRO\", \"OGKB\", \"MRKC\", \"MRKP\",\n",
    "    \n",
    "    # –¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç –∏ –ª–æ–≥–∏—Å—Ç–∏–∫–∞\n",
    "    \"AFLT\", \"FLOT\", \"NMTP\",\n",
    "    \n",
    "    # –•–∏–º–∏—è –∏ —É–¥–æ–±—Ä–µ–Ω–∏—è\n",
    "    \"PHOR\", \"AKRN\",\n",
    "    \n",
    "    # –†–∞–∑–Ω–æ–µ\n",
    "    \"PIKK\", \"MOEX\", \"AFKS\", \"LSRG\", \"RASP\", \"SVAV\", \"ENPG\",\n",
    "    \"SMLT\", \"POSI\", \"MDMG\", \"ASTR\", \"UWGN\", \"TRMK\", \"RENI\",\n",
    "    \"SOFL\", \"SGZH\", \"SELG\", \"LEAS\", \"VSMO\", \"IRKT\"\n",
    "]\n",
    "\n",
    "# –°–ª–æ–≤–∞—Ä—å —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∫–æ–º–ø–∞–Ω–∏–π\n",
    "TICKER_TO_COMPANY = {\n",
    "    \"SBER\": \"–ü–ê–û –°–±–µ—Ä–±–∞–Ω–∫\", \"SBERP\": \"–ü–ê–û –°–±–µ—Ä–±–∞–Ω–∫ (–ø)\",\n",
    "    \"GAZP\": \"–ü–ê–û –ì–∞–∑–ø—Ä–æ–º\", \"LKOH\": \"–ü–ê–û –õ—É–∫–æ–π–ª\", \n",
    "    \"GMKN\": \"–ü–ê–û –ì–ú–ö –ù–æ—Ä–Ω–∏–∫–µ–ª—å\", \"ROSN\": \"–ü–ê–û –†–æ—Å–Ω–µ—Ñ—Ç—å\",\n",
    "    \"YNDX\": \"–ü–ê–û –Ø–Ω–¥–µ–∫—Å\", \"TATN\": \"–ü–ê–û –¢–∞—Ç–Ω–µ—Ñ—Ç—å\", \"TATNP\": \"–ü–ê–û –¢–∞—Ç–Ω–µ—Ñ—Ç—å (–ø)\",\n",
    "    \"VTBR\": \"–ü–ê–û –ë–∞–Ω–∫ –í–¢–ë\", \"SBERP\": \"–ü–ê–û –°–±–µ—Ä–±–∞–Ω–∫ (–ø)\",\n",
    "    \"NVTK\": \"–ü–ê–û –ù–æ–≤–∞—Ç—ç–∫\", \"ALRS\": \"–ü–ê–û –ê–õ–†–û–°–ê\",\n",
    "    \"POLY\": \"–ü–ê–û Polymetal\", \"PLZL\": \"–ü–ê–û –ü–æ–ª—é—Å\",\n",
    "    \"MGNT\": \"–ü–ê–û –ú–∞–≥–Ω–∏—Ç\", \"MTSS\": \"–ü–ê–û –ú–¢–°\",\n",
    "    \"RTKM\": \"–ü–ê–û –†–æ—Å—Ç–µ–ª–µ–∫–æ–º\", \"RTKMP\": \"–ü–ê–û –†–æ—Å—Ç–µ–ª–µ–∫–æ–º (–ø)\",\n",
    "    \"HYDR\": \"–ü–ê–û –†—É—Å–ì–∏–¥—Ä–æ\", \"FEES\": \"–ü–ê–û –§–°–ö –ï–≠–°\",\n",
    "    \"AFKS\": \"–ü–ê–û –ê–§–ö –°–∏—Å—Ç–µ–º–∞\", \"MOEX\": \"–ü–ê–û –ú–æ—Å–∫–æ–≤—Å–∫–∞—è –±–∏—Ä–∂–∞\",\n",
    "    \"SNGS\": \"–ü–ê–û –°—É—Ä–≥—É—Ç–Ω–µ—Ñ—Ç–µ–≥–∞–∑\", \"SNGSP\": \"–ü–ê–û –°—É—Ä–≥—É—Ç–Ω–µ—Ñ—Ç–µ–≥–∞–∑ (–ø)\",\n",
    "    \"BSPB\": \"–ü–ê–û –ë–∞–Ω–∫ –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥\", \"CBOM\": \"–ü–ê–û –ú–ö–ë\",\n",
    "    \"TCSG\": \"–ü–ê–û TCS Group\", \"OZON\": \"–ü–ê–û Ozon\",\n",
    "    \"PIKK\": \"–ü–ê–û –ü–ò–ö\", \"LSRG\": \"–ü–ê–û –õ–°–†\",\n",
    "    \"CHMF\": \"–ü–ê–û –°–µ–≤–µ—Ä—Å—Ç–∞–ª—å\", \"NLMK\": \"–ü–ê–û –ù–õ–ú–ö\",\n",
    "    \"MAGN\": \"–ü–ê–û –ú–ú–ö\", \"RUAL\": \"–ü–ê–û –†—É—Å–∞–ª\",\n",
    "    \"PHOR\": \"–ü–ê–û –§–æ—Å–ê–≥—Ä–æ\", \"AKRN\": \"–ü–ê–û –ê–∫—Ä–æ–Ω\",\n",
    "    \"AFLT\": \"–ü–ê–û –ê—ç—Ä–æ—Ñ–ª–æ—Ç\", \"FLOT\": \"–ü–ê–û –°–æ–≤–∫–æ–º—Ñ–ª–æ—Ç\",\n",
    "    \"NMTP\": \"–ü–ê–û –ù–ú–¢–ü\", \"IRAO\": \"–ü–ê–û –ò–Ω—Ç–µ—Ä –†–ê–û\",\n",
    "    \"UPRO\": \"–ü–ê–û –Æ–Ω–∏–ø—Ä–æ\", \"OGKB\": \"–ü–ê–û –û–ì–ö-2\",\n",
    "    \"MRKC\": \"–ü–ê–û –†–æ—Å—Å–µ—Ç–∏ –¶–µ–Ω—Ç—Ä\", \"MRKP\": \"–ü–ê–û –†–æ—Å—Å–µ—Ç–∏ –¶–µ–Ω—Ç—Ä –∏ –ü—Ä–∏–≤–æ–ª–∂—å–µ\",\n",
    "    \"FIXP\": \"–ü–ê–û Fix Price\", \"X5\": \"–ü–ê–û X5 Retail Group\",\n",
    "    \"LENT\": \"–ü–ê–û –õ–µ–Ω—Ç–∞\", \"MVID\": \"–ü–ê–û –ú.–í–∏–¥–µ–æ\",\n",
    "    \"BELU\": \"–ü–ê–û –ù–æ–≤–∞–ë–µ–≤ –ì—Ä—É–ø–ø\", \"AQUA\": \"–ü–ê–û –ò–Ω–ê—Ä–∫—Ç–∏–∫–∞\",\n",
    "    \"SMLT\": \"–ì–ö –°–∞–º–æ–ª–µ—Ç\", \"POSI\": \"–ì—Ä—É–ø–ø–∞ –ü–æ–∑–∏—Ç–∏–≤\",\n",
    "    \"MDMG\": \"–ú–ö–ü–ê–û –ú–î –ú–µ–¥–∏–∫–∞–ª –ì—Ä—É–ø\", \"ASTR\": \"–ì—Ä—É–ø–ø–∞ –ê—Å—Ç—Ä–∞\",\n",
    "    \"UWGN\": \"–ü–ê–û –ù–ü–ö –û–í–ö\", \"TRMK\": \"–ü–ê–û –¢–ú–ö\",\n",
    "    \"RENI\": \"–ü–ê–û –†–µ–Ω–µ—Å—Å–∞–Ω—Å –°—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏–µ\", \"SOFL\": \"–ü–ê–û –°–æ—Ñ—Ç–ª–∞–π–Ω\",\n",
    "    \"SGZH\": \"–ü–ê–û –°–µ–≥–µ–∂–∞\", \"SELG\": \"–ü–ê–û –°–µ–ª–∏–≥–¥–∞—Ä\",\n",
    "    \"LEAS\": \"–ü–ê–û –õ–ö –ï–≤—Ä–æ–ø–ª–∞–Ω\", \"VSMO\": \"–ü–ê–û –í–°–ú–ü–û-–ê–í–ò–°–ú–ê\",\n",
    "    \"IRKT\": \"–ü–ê–û –ò—Ä–∫—É—Ç\", \"RASP\": \"–ü–ê–û –†–∞—Å–ø–∞–¥—Å–∫–∞—è\",\n",
    "    \"SVAV\": \"–ü–ê–û –°–æ–ª–ª–µ—Ä—Å\", \"ENPG\": \"–ú–ö–ü–ê–û –≠–Ω+ –ì—Ä—É–ø\",\n",
    "    \"TTLK\": \"–ü–ê–û –¢-–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏\"\n",
    "}\n",
    "\n",
    "class DatabaseManager:\n",
    "    def __init__(self, db_config):\n",
    "        self.db_config = db_config\n",
    "        self.conn = None\n",
    "        self.connect()\n",
    "        self.create_tables()\n",
    "    \n",
    "    def connect(self):\n",
    "        \"\"\"–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö\"\"\"\n",
    "        try:\n",
    "            self.conn = psycopg2.connect(**self.db_config)\n",
    "            print(\"‚úÖ –£—Å–ø–µ—à–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ PostgreSQL\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ PostgreSQL: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def create_tables(self):\n",
    "        \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç\"\"\"\n",
    "        try:\n",
    "            with self.conn.cursor() as cursor:\n",
    "                # –¢–∞–±–ª–∏—Ü–∞ –∫–æ–º–ø–∞–Ω–∏–π\n",
    "                cursor.execute(\"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS companies (\n",
    "                        id SERIAL PRIMARY KEY,\n",
    "                        ticker VARCHAR(20) UNIQUE NOT NULL,\n",
    "                        name TEXT NOT NULL,\n",
    "                        figi VARCHAR(50) UNIQUE NOT NULL,\n",
    "                        currency VARCHAR(10),\n",
    "                        lot INTEGER,\n",
    "                        min_price_increment DECIMAL(10,6),\n",
    "                        sector TEXT,\n",
    "                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                    )\n",
    "                \"\"\")\n",
    "                \n",
    "                # –¢–∞–±–ª–∏—Ü–∞ —Å–≤–µ—á–µ–π\n",
    "                cursor.execute(\"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS candles (\n",
    "                        id SERIAL PRIMARY KEY,\n",
    "                        ticker VARCHAR(20) REFERENCES companies(ticker),\n",
    "                        datetime TIMESTAMP NOT NULL,\n",
    "                        open DECIMAL(15,6),\n",
    "                        high DECIMAL(15,6),\n",
    "                        low DECIMAL(15,6),\n",
    "                        close DECIMAL(15,6),\n",
    "                        volume BIGINT,\n",
    "                        is_complete BOOLEAN,\n",
    "                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                        UNIQUE(ticker, datetime)\n",
    "                    )\n",
    "                \"\"\")\n",
    "                \n",
    "                # –¢–∞–±–ª–∏—Ü–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å–±–æ—Ä–æ–≤\n",
    "                cursor.execute(\"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS collection_metadata (\n",
    "                        id SERIAL PRIMARY KEY,\n",
    "                        collection_timestamp TIMESTAMP NOT NULL,\n",
    "                        total_searched INTEGER NOT NULL,\n",
    "                        found_stocks INTEGER NOT NULL,\n",
    "                        not_found_count INTEGER NOT NULL,\n",
    "                        collection_years INTEGER NOT NULL,\n",
    "                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                    )\n",
    "                \"\"\")\n",
    "                \n",
    "                # –¢–∞–±–ª–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤\n",
    "                cursor.execute(\"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS not_found_tickers (\n",
    "                        id SERIAL PRIMARY KEY,\n",
    "                        collection_id INTEGER REFERENCES collection_metadata(id),\n",
    "                        ticker VARCHAR(20) NOT NULL,\n",
    "                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                    )\n",
    "                \"\"\")\n",
    "                \n",
    "                # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n",
    "                cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_candles_ticker_datetime ON candles(ticker, datetime)\")\n",
    "                cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_candles_datetime ON candles(datetime)\")\n",
    "                cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_companies_ticker ON companies(ticker)\")\n",
    "                \n",
    "                self.conn.commit()\n",
    "                print(\"‚úÖ –¢–∞–±–ª–∏—Ü—ã —Å–æ–∑–¥–∞–Ω—ã/–ø—Ä–æ–≤–µ—Ä–µ–Ω—ã\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü: {e}\")\n",
    "            self.conn.rollback()\n",
    "            raise\n",
    "    \n",
    "    def save_company_info(self, company_info):\n",
    "        \"\"\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–º–ø–∞–Ω–∏–∏\"\"\"\n",
    "        try:\n",
    "            with self.conn.cursor() as cursor:\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO companies (ticker, name, figi, currency, lot, min_price_increment, sector)\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "                    ON CONFLICT (ticker) DO UPDATE SET\n",
    "                        name = EXCLUDED.name,\n",
    "                        figi = EXCLUDED.figi,\n",
    "                        currency = EXCLUDED.currency,\n",
    "                        lot = EXCLUDED.lot,\n",
    "                        min_price_increment = EXCLUDED.min_price_increment,\n",
    "                        sector = EXCLUDED.sector,\n",
    "                        updated_at = CURRENT_TIMESTAMP\n",
    "                \"\"\", (\n",
    "                    company_info['ticker'],\n",
    "                    company_info['name'],\n",
    "                    company_info['figi'],\n",
    "                    company_info['currency'],\n",
    "                    company_info['lot'],\n",
    "                    company_info['min_price_increment'],\n",
    "                    company_info['sector']\n",
    "                ))\n",
    "                self.conn.commit()\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–∏ {company_info['ticker']}: {e}\")\n",
    "            self.conn.rollback()\n",
    "            return False\n",
    "    \n",
    "    def save_candles_batch(self, ticker, candles_df):\n",
    "        \"\"\"–ü–∞–∫–µ—Ç–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–≤–µ—á–µ–π\"\"\"\n",
    "        if candles_df.empty:\n",
    "            return True\n",
    "            \n",
    "        try:\n",
    "            with self.conn.cursor() as cursor:\n",
    "                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏\n",
    "                data_tuples = [\n",
    "                    (\n",
    "                        ticker,\n",
    "                        row['datetime'],\n",
    "                        row['open'],\n",
    "                        row['high'],\n",
    "                        row['low'],\n",
    "                        row['close'],\n",
    "                        row['volume'],\n",
    "                        row['is_complete']\n",
    "                    )\n",
    "                    for _, row in candles_df.iterrows()\n",
    "                ]\n",
    "                \n",
    "                # –ü–∞–∫–µ—Ç–Ω–∞—è –≤—Å—Ç–∞–≤–∫–∞\n",
    "                execute_batch(cursor, \"\"\"\n",
    "                    INSERT INTO candles (ticker, datetime, open, high, low, close, volume, is_complete)\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    ON CONFLICT (ticker, datetime) DO UPDATE SET\n",
    "                        open = EXCLUDED.open,\n",
    "                        high = EXCLUDED.high,\n",
    "                        low = EXCLUDED.low,\n",
    "                        close = EXCLUDED.close,\n",
    "                        volume = EXCLUDED.volume,\n",
    "                        is_complete = EXCLUDED.is_complete\n",
    "                \"\"\", data_tuples)\n",
    "                \n",
    "                self.conn.commit()\n",
    "                print(f\"   üìä –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(data_tuples)} —Å–≤–µ—á–µ–π –¥–ª—è {ticker}\")\n",
    "                return True\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–≤–µ—á–µ–π –¥–ª—è {ticker}: {e}\")\n",
    "            self.conn.rollback()\n",
    "            return False\n",
    "    \n",
    "    def save_collection_metadata(self, metadata, not_found_tickers):\n",
    "        \"\"\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å–±–æ—Ä–∞\"\"\"\n",
    "        try:\n",
    "            with self.conn.cursor() as cursor:\n",
    "                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO collection_metadata \n",
    "                    (collection_timestamp, total_searched, found_stocks, not_found_count, collection_years)\n",
    "                    VALUES (%s, %s, %s, %s, %s)\n",
    "                    RETURNING id\n",
    "                \"\"\", (\n",
    "                    metadata['timestamp'],\n",
    "                    metadata['total_searched'],\n",
    "                    metadata['found_stocks'],\n",
    "                    metadata['not_found_count'],\n",
    "                    metadata['collection_years']\n",
    "                ))\n",
    "                \n",
    "                collection_id = cursor.fetchone()[0]\n",
    "                \n",
    "                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–∏–∫–µ—Ä—ã\n",
    "                if not_found_tickers:\n",
    "                    not_found_tuples = [(collection_id, ticker) for ticker in not_found_tickers]\n",
    "                    execute_batch(cursor, \"\"\"\n",
    "                        INSERT INTO not_found_tickers (collection_id, ticker)\n",
    "                        VALUES (%s, %s)\n",
    "                    \"\"\", not_found_tuples)\n",
    "                \n",
    "                self.conn.commit()\n",
    "                print(f\"‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã (ID: {collection_id})\")\n",
    "                return collection_id\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}\")\n",
    "            self.conn.rollback()\n",
    "            return None\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö\"\"\"\n",
    "        if self.conn:\n",
    "            self.conn.close()\n",
    "            print(\"‚úÖ –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å PostgreSQL –∑–∞–∫—Ä—ã—Ç–æ\")\n",
    "\n",
    "class CompleteDataCollector:\n",
    "    def __init__(self, token):\n",
    "        self.token = token\n",
    "    \n",
    "    def find_available_stocks(self):\n",
    "        \"\"\"–ü–æ–∏—Å–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞–∫—Ü–∏–π –∏–∑ —Å–ø–∏—Å–∫–∞\"\"\"\n",
    "        print(f\"–í—Å–µ–≥–æ —Ç–∏–∫–µ—Ä–æ–≤ –≤ —Å–ø–∏—Å–∫–µ: {len(ALL_TICKERS)}\")\n",
    "        \n",
    "        with Client(self.token) as client:\n",
    "            try:\n",
    "                all_shares = client.instruments.shares().instruments\n",
    "                print(f\"–í—Å–µ–≥–æ –∞–∫—Ü–∏–π –≤ Tinkoff API: {len(all_shares)}\")\n",
    "                \n",
    "                available_stocks = []\n",
    "                not_found = []\n",
    "                \n",
    "                # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞\n",
    "                shares_by_ticker = {}\n",
    "                for share in all_shares:\n",
    "                    shares_by_ticker[share.ticker] = share\n",
    "                \n",
    "                for ticker in ALL_TICKERS:\n",
    "                    if ticker in shares_by_ticker:\n",
    "                        share = shares_by_ticker[ticker]\n",
    "                        \n",
    "                        if share.currency == 'rub' and share.buy_available_flag:\n",
    "                            stock_info = {\n",
    "                                'ticker': share.ticker,\n",
    "                                'figi': share.figi,\n",
    "                                'name': TICKER_TO_COMPANY.get(ticker, share.name),\n",
    "                                'api_name': share.name,\n",
    "                                'currency': share.currency,\n",
    "                                'lot': share.lot,\n",
    "                                'min_price_increment': self._quotation_to_float(share.min_price_increment),\n",
    "                                'sector': share.sector if hasattr(share, 'sector') else '–ù–µ —É–∫–∞–∑–∞–Ω'\n",
    "                            }\n",
    "                            available_stocks.append(stock_info)\n",
    "                            print(f\"{ticker}: {stock_info['name']}\")\n",
    "                        else:\n",
    "                            not_found.append(ticker)\n",
    "                            print(f\"{ticker}: –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è —Ç–æ—Ä–≥–æ–≤–ª–∏\")\n",
    "                    else:\n",
    "                        not_found.append(ticker)\n",
    "                        print(f\"{ticker}: –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n",
    "                \n",
    "                print(f\"\\n –ò–¢–û–ì–û:\")\n",
    "                print(f\"   –ù–∞–π–¥–µ–Ω–æ: {len(available_stocks)} –∞–∫—Ü–∏–π\")\n",
    "                print(f\"   –ù–µ –Ω–∞–π–¥–µ–Ω–æ: {len(not_found)} –∞–∫—Ü–∏–π\")\n",
    "                \n",
    "                if not_found:\n",
    "                    print(f\"   –ù–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ: {', '.join(not_found)}\")\n",
    "                \n",
    "                return available_stocks, not_found\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –∞–∫—Ü–∏–π: {e}\")\n",
    "                return [], ALL_TICKERS\n",
    "    \n",
    "    def collect_extended_data(self, stocks_info, years=10):\n",
    "        \"\"\"–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–µ–π\"\"\"\n",
    "        all_data = {}\n",
    "        failed_tickers = []\n",
    "        \n",
    "        print(f\"\\n –ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∑–∞ {years} –ª–µ—Ç...\")\n",
    "        print(f\" –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {len(stocks_info)} –∞–∫—Ü–∏–π\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for i, stock in enumerate(stocks_info, 1):\n",
    "            try:\n",
    "                print(f\" [{i:2d}/{len(stocks_info)}] {stock['ticker']}...\")\n",
    "                \n",
    "                # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —á–∞—Å—Ç—è–º\n",
    "                candles_df = self._collect_data_in_chunks(stock['figi'], years=years)\n",
    "                \n",
    "                if candles_df is not None and len(candles_df) > 100:\n",
    "                    all_data[stock['ticker']] = {\n",
    "                        'data': candles_df,\n",
    "                        'info': stock,\n",
    "                        'first_date': candles_df['datetime'].min(),\n",
    "                        'last_date': candles_df['datetime'].max(),\n",
    "                        'candle_count': len(candles_df),\n",
    "                        'data_quality': self._assess_data_quality(candles_df),\n",
    "                        'period_years': (candles_df['datetime'].max() - candles_df['datetime'].min()).days / 365.25\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"   –£—Å–ø–µ—à–Ω–æ: {len(candles_df)} —Å–≤–µ—á–µ–π\")\n",
    "                    print(f\"   –ü–µ—Ä–∏–æ–¥: {candles_df['datetime'].min().date()} - {candles_df['datetime'].max().date()}\")\n",
    "                    \n",
    "                else:\n",
    "                    failed_tickers.append(stock['ticker'])\n",
    "                    print(f\"   –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö: {len(candles_df) if candles_df else 0} —Å–≤–µ—á–µ–π\")\n",
    "                \n",
    "                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏\n",
    "                time.sleep(0.3)\n",
    "                \n",
    "            except Exception as e:\n",
    "                failed_tickers.append(stock['ticker'])\n",
    "                print(f\"   –û—à–∏–±–∫–∞: {e}\")\n",
    "                continue\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "        print(f\"–£—Å–ø–µ—à–Ω–æ —Å–æ–±—Ä–∞–Ω–æ: {len(all_data)} –∞–∫—Ü–∏–π\")\n",
    "        if failed_tickers:\n",
    "            print(f\" –ü—Ä–æ–±–ª–µ–º—ã —Å: {', '.join(failed_tickers)}\")\n",
    "        \n",
    "        return all_data\n",
    "    \n",
    "    def _collect_data_in_chunks(self, figi, years=10, chunk_years=3):\n",
    "        \"\"\"–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —á–∞—Å—Ç—è–º–∏\"\"\"\n",
    "        all_chunks = []\n",
    "        end_time = datetime.utcnow()\n",
    "        \n",
    "        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø–µ—Ä–∏–æ–¥—ã\n",
    "        for chunk_start in range(0, years, chunk_years):\n",
    "            chunk_end = min(chunk_start + chunk_years, years)\n",
    "            \n",
    "            start_time = end_time - timedelta(days=chunk_end * 365)\n",
    "            chunk_start_time = end_time - timedelta(days=chunk_start * 365)\n",
    "            \n",
    "            try:\n",
    "                chunk_data = self._get_candles_period(figi, start_time, chunk_start_time)\n",
    "                if chunk_data is not None and len(chunk_data) > 0:\n",
    "                    all_chunks.append(chunk_data)\n",
    "                \n",
    "                time.sleep(0.2)\n",
    "                \n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —á–∞–Ω–∫–∏\n",
    "        if all_chunks:\n",
    "            combined_df = pd.concat(all_chunks, ignore_index=True)\n",
    "            combined_df = combined_df.drop_duplicates(subset=['datetime']).sort_values('datetime')\n",
    "            return combined_df\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def _get_candles_period(self, figi, start_time, end_time, interval=CandleInterval.CANDLE_INTERVAL_DAY):\n",
    "        \"\"\"–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤–µ—á–µ–π –∑–∞ –ø–µ—Ä–∏–æ–¥\"\"\"\n",
    "        with Client(self.token) as client:\n",
    "            try:\n",
    "                candles = client.get_all_candles(\n",
    "                    figi=figi,\n",
    "                    from_=start_time,\n",
    "                    to=end_time,\n",
    "                    interval=interval\n",
    "                )\n",
    "                return self._candles_to_dataframe(candles)\n",
    "            except Exception:\n",
    "                return pd.DataFrame()\n",
    "    \n",
    "    def _candles_to_dataframe(self, candles):\n",
    "        \"\"\"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å–≤–µ—á–µ–π –≤ DataFrame\"\"\"\n",
    "        data = []\n",
    "        for candle in candles:\n",
    "            data.append({\n",
    "                'datetime': candle.time,\n",
    "                'open': self._quotation_to_float(candle.open),\n",
    "                'high': self._quotation_to_float(candle.high),\n",
    "                'low': self._quotation_to_float(candle.low),\n",
    "                'close': self._quotation_to_float(candle.close),\n",
    "                'volume': candle.volume,\n",
    "                'is_complete': candle.is_complete\n",
    "            })\n",
    "        return pd.DataFrame(data) if data else pd.DataFrame()\n",
    "    \n",
    "    def _quotation_to_float(self, quotation):\n",
    "        \"\"\"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è Quotation –≤ float\"\"\"\n",
    "        if hasattr(quotation, 'units') and hasattr(quotation, 'nano'):\n",
    "            return quotation.units + quotation.nano / 1e9\n",
    "        return float(quotation)\n",
    "    \n",
    "    def _assess_data_quality(self, df):\n",
    "        \"\"\"–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö\"\"\"\n",
    "        if len(df) == 0:\n",
    "            return \"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö\"\n",
    "        \n",
    "        missing_data = df[['open', 'high', 'low', 'close']].isnull().sum().sum()\n",
    "        zero_volume = (df['volume'] == 0).sum()\n",
    "        \n",
    "        quality_score = (len(df) - missing_data - zero_volume/10) / len(df)\n",
    "        \n",
    "        if quality_score > 0.95:\n",
    "            return \"–û—Ç–ª–∏—á–Ω–æ–µ\"\n",
    "        elif quality_score > 0.8:\n",
    "            return \"–•–æ—Ä–æ—à–µ–µ\"\n",
    "        elif quality_score > 0.6:\n",
    "            return \"–£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–µ\"\n",
    "        else:\n",
    "            return \"–ü–ª–æ—Ö–æ–µ\"\n",
    "\n",
    "class CompleteDataDBManager:\n",
    "    def __init__(self, db_config):\n",
    "        self.db_manager = DatabaseManager(db_config)\n",
    "    \n",
    "    def save_all_data(self, all_data, available_stocks, not_found_tickers, collection_years):\n",
    "        \"\"\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö\"\"\"\n",
    "        timestamp = datetime.now()\n",
    "        \n",
    "        print(f\"\\n –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ PostgreSQL...\")\n",
    "        \n",
    "        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–º–ø–∞–Ω–∏—è—Ö\n",
    "        companies_saved = 0\n",
    "        for stock in available_stocks:\n",
    "            if self.db_manager.save_company_info(stock):\n",
    "                companies_saved += 1\n",
    "        print(f\"   –ö–æ–º–ø–∞–Ω–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {companies_saved}/{len(available_stocks)}\")\n",
    "        \n",
    "        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–≤–µ—á–µ–π\n",
    "        candles_saved = 0\n",
    "        for ticker, data in all_data.items():\n",
    "            if self.db_manager.save_candles_batch(ticker, data['data']):\n",
    "                candles_saved += 1\n",
    "        print(f\"   –°–≤–µ—á–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {candles_saved}/{len(all_data)}\")\n",
    "        \n",
    "        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö\n",
    "        metadata = {\n",
    "            'timestamp': timestamp,\n",
    "            'total_searched': len(ALL_TICKERS),\n",
    "            'found_stocks': len(all_data),\n",
    "            'not_found_count': len(not_found_tickers),\n",
    "            'collection_years': collection_years\n",
    "        }\n",
    "        \n",
    "        collection_id = self.db_manager.save_collection_metadata(metadata, not_found_tickers)\n",
    "        \n",
    "        # –°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç—á–µ—Ç–∞\n",
    "        self._create_analysis_report(all_data, timestamp)\n",
    "        \n",
    "        return timestamp, collection_id\n",
    "    \n",
    "    def _create_analysis_report(self, all_data, timestamp):\n",
    "        \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç—á–µ—Ç–∞\"\"\"\n",
    "        analysis_data = []\n",
    "        \n",
    "        for ticker, data in all_data.items():\n",
    "            df = data['data']\n",
    "            if len(df) > 0:\n",
    "                returns = df['close'].pct_change()\n",
    "                \n",
    "                analysis_data.append({\n",
    "                    'ticker': ticker,\n",
    "                    'name': data['info']['name'],\n",
    "                    'sector': data['info']['sector'],\n",
    "                    'first_date': data['first_date'].strftime('%Y-%m-%d'),\n",
    "                    'last_date': data['last_date'].strftime('%Y-%m-%d'),\n",
    "                    'total_candles': len(df),\n",
    "                    'period_years': round(data['period_years'], 1),\n",
    "                    'start_price': df['close'].iloc[0],\n",
    "                    'end_price': df['close'].iloc[-1],\n",
    "                    'total_return_percent': (df['close'].iloc[-1] - df['close'].iloc[0]) / df['close'].iloc[0] * 100,\n",
    "                    'max_price': df['high'].max(),\n",
    "                    'min_price': df['low'].min(),\n",
    "                    'avg_daily_volume': df['volume'].mean(),\n",
    "                    'volatility_percent': returns.std() * 100 if len(returns) > 1 else 0,\n",
    "                    'data_quality': data['data_quality']\n",
    "                })\n",
    "        \n",
    "        analysis_df = pd.DataFrame(analysis_data)\n",
    "        \n",
    "        # –í—ã–≤–æ–¥ —Å–≤–æ–¥–∫–∏ –≤ –∫–æ–Ω—Å–æ–ª—å\n",
    "        print(f\"\\n –°–í–û–î–ö–ê –ü–û –í–°–ï–ú –ö–û–ú–ü–ê–ù–ò–Ø–ú:\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\" –ê–∫—Ü–∏–π —Å–æ–±—Ä–∞–Ω–æ: {len(analysis_df)}\")\n",
    "        print(f\" –í—Å–µ–≥–æ —Å–≤–µ—á–µ–π: {analysis_df['total_candles'].sum():,}\")\n",
    "        print(f\" –°—Ä–µ–¥–Ω–∏–π –ø–µ—Ä–∏–æ–¥: {analysis_df['period_years'].mean():.1f} –ª–µ—Ç\")\n",
    "        \n",
    "        # –¢–æ–ø-5 –ø–æ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏\n",
    "        if len(analysis_df) > 0:\n",
    "            print(f\"\\n –¢–û–ü-5 –ü–û –î–û–•–û–î–ù–û–°–¢–ò:\")\n",
    "            top_return = analysis_df.nlargest(5, 'total_return_percent')[['ticker', 'name', 'total_return_percent']]\n",
    "            for _, row in top_return.iterrows():\n",
    "                symbol = \"üü¢\" if row['total_return_percent'] > 0 else \"üî¥\"\n",
    "                print(f\"   {symbol} {row['ticker']}: {row['total_return_percent']:+.1f}%\")\n",
    "    \n",
    "    def close_connection(self):\n",
    "        \"\"\"–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö\"\"\"\n",
    "        self.db_manager.close()\n",
    "\n",
    "def show_database_stats(db_config):\n",
    "    \"\"\"–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö\"\"\"\n",
    "    try:\n",
    "        db_manager = DatabaseManager(db_config)\n",
    "        \n",
    "        with db_manager.conn.cursor() as cursor:\n",
    "            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ–º–ø–∞–Ω–∏–π\n",
    "            cursor.execute(\"SELECT COUNT(*) FROM companies\")\n",
    "            companies_count = cursor.fetchone()[0]\n",
    "            \n",
    "            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–≤–µ—á–µ–π\n",
    "            cursor.execute(\"SELECT COUNT(*) FROM candles\")\n",
    "            candles_count = cursor.fetchone()[0]\n",
    "            \n",
    "            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–∞—Ç–∞–º\n",
    "            cursor.execute(\"SELECT MIN(datetime), MAX(datetime) FROM candles\")\n",
    "            min_date, max_date = cursor.fetchone()\n",
    "            \n",
    "            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–±–æ—Ä–∫–∞–º\n",
    "            cursor.execute(\"SELECT COUNT(*), MAX(collection_timestamp) FROM collection_metadata\")\n",
    "            collections_count, last_collection = cursor.fetchone()\n",
    "            \n",
    "        db_manager.close()\n",
    "        \n",
    "        print(f\"\\n –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ë–ê–ó–´ –î–ê–ù–ù–´–•:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\" –ö–æ–º–ø–∞–Ω–∏–π: {companies_count}\")\n",
    "        print(f\" –°–≤–µ—á–µ–π: {candles_count:,}\")\n",
    "        print(f\" –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {min_date.date()} - {max_date.date()}\")\n",
    "        print(f\" –°–±–æ—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö: {collections_count}\")\n",
    "        print(f\" –ü–æ—Å–ª–µ–¥–Ω—è—è —Å–±–æ—Ä–∫–∞: {last_collection}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}\")\n",
    "\n",
    "def main_complete_collection():\n",
    "    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö PostgreSQL\n",
    "    DB_CONFIG = {\n",
    "        'dbname': 'russian-stocks-prediction-ml-dl',\n",
    "        'user': 'root',\n",
    "        'password': 'groot',\n",
    "        'host': '185.70.105.233',\n",
    "        'port': '5432'\n",
    "    }\n",
    "    \n",
    "    # –¢–û–ö–ï–ù Tinkoff\n",
    "    TINKOFF_TOKEN = TOKEN\n",
    "    \n",
    "    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏\n",
    "    COLLECTION_YEARS = 10  # –õ–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏\n",
    "    \n",
    "    print(\" –ü–û–õ–ù–´–ô –°–ë–û–† –î–ê–ù–ù–´–• –í POSTGRESQL\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\" –ö–æ–º–ø–∞–Ω–∏–π –≤ —Å–ø–∏—Å–∫–µ: {len(ALL_TICKERS)}\")\n",
    "    print(f\" –ü–µ—Ä–∏–æ–¥ —Å–±–æ—Ä–∞: {COLLECTION_YEARS} –ª–µ—Ç\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "        collector = CompleteDataCollector(TINKOFF_TOKEN)\n",
    "        data_manager = CompleteDataDBManager(DB_CONFIG)\n",
    "        \n",
    "        # –®–∞–≥ 1: –ü–æ–∏—Å–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞–∫—Ü–∏–π\n",
    "        available_stocks, not_found = collector.find_available_stocks()\n",
    "        \n",
    "        if not available_stocks:\n",
    "            print(\"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞–∫—Ü–∏–π!\")\n",
    "            return\n",
    "        \n",
    "        # –®–∞–≥ 2: –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö\n",
    "        print(f\"\\n –ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∑–∞ {COLLECTION_YEARS} –ª–µ—Ç...\")\n",
    "        all_data = collector.collect_extended_data(available_stocks, years=COLLECTION_YEARS)\n",
    "        \n",
    "        if all_data:\n",
    "            # –®–∞–≥ 3: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö\n",
    "            timestamp, collection_id = data_manager.save_all_data(\n",
    "                all_data, available_stocks, not_found, COLLECTION_YEARS\n",
    "            )\n",
    "            \n",
    "            print(f\"\\n –ü–û–õ–ù–´–ô –°–ë–û–† –î–ê–ù–ù–´–• –ó–ê–í–ï–†–®–ï–ù!\")\n",
    "            print(f\" –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ PostgreSQL\")\n",
    "            print(f\" ID —Å–±–æ—Ä–∫–∏: {collection_id}\")\n",
    "            \n",
    "            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n",
    "            show_database_stats(DB_CONFIG)\n",
    "            \n",
    "        else:\n",
    "            print(\" –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ\")\n",
    "        \n",
    "        # –ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è\n",
    "        data_manager.close_connection()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}\")\n",
    "\n",
    "def quick_db_stats(db_config):\n",
    "    \"\"\"–ë—ã—Å—Ç—Ä–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö\"\"\"\n",
    "    try:\n",
    "        db_manager = DatabaseManager(db_config)\n",
    "        \n",
    "        with db_manager.conn.cursor() as cursor:\n",
    "            # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT \n",
    "                    COUNT(DISTINCT ticker) as companies_count,\n",
    "                    COUNT(*) as candles_count,\n",
    "                    MIN(datetime) as first_date,\n",
    "                    MAX(datetime) as last_date\n",
    "                FROM candles\n",
    "            \"\"\")\n",
    "            stats = cursor.fetchone()\n",
    "            \n",
    "            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–æ–º–ø–∞–Ω–∏—è–º\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT ticker, COUNT(*) as candle_count\n",
    "                FROM candles \n",
    "                GROUP BY ticker \n",
    "                ORDER BY candle_count DESC\n",
    "                LIMIT 10\n",
    "            \"\"\")\n",
    "            top_companies = cursor.fetchall()\n",
    "        \n",
    "        db_manager.close()\n",
    "        \n",
    "        print(f\"\\n –ë–´–°–¢–†–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:\")\n",
    "        print(f\" –ö–æ–º–ø–∞–Ω–∏–π: {stats[0]}\")\n",
    "        print(f\" –°–≤–µ—á–µ–π: {stats[1]:,}\")\n",
    "        print(f\" –ü–µ—Ä–∏–æ–¥: {stats[2].date()} - {stats[3].date()}\")\n",
    "        \n",
    "        print(f\"\\n –¢–û–ü-10 –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–≤–µ—á–µ–π:\")\n",
    "        for ticker, count in top_companies:\n",
    "            print(f\"   {ticker}: {count:,} —Å–≤–µ—á–µ–π\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö\n",
    "    DB_CONFIG = {\n",
    "        'dbname': 'russian-stocks-prediction-ml-dl',\n",
    "        'user': 'root',\n",
    "        'password': 'groot',\n",
    "        'host': '185.70.105.233',\n",
    "        'port': '5432'\n",
    "    }\n",
    "    \n",
    "    # –û—Å–Ω–æ–≤–Ω–æ–π —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö\n",
    "    main_complete_collection()\n",
    "    \n",
    "    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: –±—ã—Å—Ç—Ä–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "    quick_db_stats(DB_CONFIG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
